1)Задание 14: Neural Style Transfer
Задача: реализовать Neural Style Transfer для применения стиля одного
изображения к другому.
Требования:
Использовать VGG19 как feature extractor
Gram matrix для стиля
Content loss и Style loss
Оптимизация изображения через gradient descent
Код-заготовка (Python):
import tensorflow as tf
class NeuralStyleTransfer:
 def __init__(self, content_layers, style_layers):
 self.content_layers = content_layers
 self.style_layers = style_layers

 # TODO: Загрузить VGG19
 # self.model = tf.keras.applications.VGG19(include_top=False,
weights='imagenet')
 # Установить trainable=False

 # TODO: Создать style transfer модель
 # которая возвращает content и style features

 def gram_matrix(self, tensor):
 # TODO: Вычислить Gram matrix
 # 1. Получить shape: (height, width, channels)
 # 2. Reshape в (height*width, channels)
 # 3. Вычислить матрицу корреляции: G = X @ X^T
 # 4. Нормализовать
 pass

 def content_loss(self, content_features, generated_features):
 # TODO: Вычислить content loss (MSE)
 # Сравнивает feature maps оригинального и сгенерированного изображения
 pass

 def style_loss(self, style_features, generated_features):
 # TODO: Вычислить style loss
57
 # Сравнивает Gram matrices
 total_loss = 0
 for style_feat, gen_feat in zip(style_features, generated_features):
 style_gram = self.gram_matrix(style_feat)
 gen_gram = self.gram_matrix(gen_feat)
 total_loss += tf.reduce_mean(tf.square(style_gram - gen_gram))

 return total_loss

 def total_loss(self, content_image, style_image, generated_image,
 content_weight=1e4, style_weight=1e-2):
 # TODO: Комбинировать content и style losses
 pass

 def transfer_style(self, content_image, style_image, epochs=1000,
 content_weight=1e4, style_weight=1e-2):
 # TODO: Основной цикл оптимизации
 # 1. Инициализировать generated_image от content_image
 # 2. Создать переменную для оптимизации
 # 3. Цикл по epochs:
 # a. Вычислить losses
 # b. Вычислить градиент
 # c. Обновить изображение через optimizer
 # 4. Вернуть финальное изображение
 pass
# Что нужно дополнить:
# 1. Загрузку VGG19 и создание feature extractor
# 2. Реализацию Gram matrix
# 3. Content loss функцию
# 4. Style loss функцию
# 5. Основной цикл оптимизации с Adam optimizer
# 6. Визуализацию процесса применения стиля


2)Алгоритм работы НС по блокам:
Блок 1. Подготовка данных и препроцессинг.
В начале кода задаются базовые настройки: размер изображения (IMG_SIZE = 250) и выполняется очистка сессии Keras для исключения влияния предыдущих вычислений. Далее определяются две вспомогательные функции для работы с изображениями: load_img() — загружает изображение по пути, декодирует его в RGB‑формат, нормализует значения пикселей в диапазон [0.0, 1.0], масштабирует так, чтобы длинная сторона соответствовала IMG_SIZE, и добавляет размерность batch ([1, h, w, 3]); deprocess_img() — выполняет обратную операцию: убирает размерность batch и ограничивает значения пикселей в диапазоне [0.0, 1.0], возвращая массив NumPy для визуализации.

Блок 2. Инициализация модели-экстрактора признаков.
Класс NeuralStyleTransfer при создании экземпляра: принимает списки названий слоёв VGG19, ответственных за признаки контента и стиля; загружает предобученную на ImageNet модель VGG19 без полносвязных слоёв (include_top=False) и замораживает её веса (trainable = False); формирует подмодель, которая на входе принимает изображение, а на выходе возвращает активации выбранных слоёв (сначала слои стиля, затем слои контента). Это позволяет использовать VGG19 как фиксированный экстрактор признаков, не обновляя её веса в процессе обучения.

Блок 3. Извлечение признаков контента и стиля.
Метод _get_feature_representations(): умножает входные изображения на 255, чтобы вернуть значения пикселей в исходный диапазон [0, 255]; применяет предобработку VGG19 (preprocess_input), которая выполняет центрирование по каналам ImageNet; пропускает изображения через подмодель и получает списки активаций для каждого выбранного слоя; разделяет выходы модели: первые num_style выходов соответствуют признакам стиля, следующие num_content выходов — признакам контента. Таким образом, получаются репрезентации исходного контента и стиля в пространстве признаков VGG19.

Блок 4. Вычисление Gram‑матрицы для оценки стиля.
Метод gram_matrix() преобразует тензор признаков слоя (b, h, w, c) в матрицу (h×w, c), затем вычисляет скалярное произведение транспонированной матрицы на себя: G = X^T*X. Результат нормируется на число элементов (h × w), получая симметричную матрицу размера (c, c). Gram‑матрица кодирует статистические взаимосвязи между каналами признаков, что эффективно описывает текстурные характеристики изображения.

Блок 5. Расчёт функций потерь.
content_loss() вычисляет среднеквадратичную ошибку (MSE) между признаками контента исходного изображения и генерируемого. Для каждого выбранного слоя суммируется MSE между соответствующими активациями. style_loss() аналогично вычисляет MSE между Gram‑матрицами признаков стиля исходного и генерируемого изображений для каждого слоя стиля. Это позволяет сопоставить статистические характеристики текстур. total_loss() комбинирует две потери с весовыми коэффициентами: L(total) = w(content)*L(content) + w(style)*L(style). По умолчанию вес контента значительно выше, чтобы сохранить структуру объекта.

Блок 6. Шаг оптимизации.
Метод _train_step(), ускоренный декоратором @tf.function: подготавливает генерируемое изображение (умножает на 255 и применяет предобработку VGG19); пропускает его через подмодель, получая признаки стиля и контента; вычисляет полную потерю и её компоненты; с помощью GradientTape вычисляет градиенты потери по пикселям генерируемого изображения; обновляет пиксели с помощью оптимизатора Adam; ограничивает значения пикселей в диапазоне [0.0, 1.0] для корректной визуализации.

Блок 7. Основной цикл переноса стиля.
Метод transfer_style(): извлекает признаки контента и стиля из исходных изображений; инициализирует генерируемое изображение как копию контента (переменная tf.Variable); создаёт оптимизатор Adam с заданной скоростью обучения; запускает цикл по эпохам, на каждой итерации вызывая _train_step() и сохраняя значения потерь; выводит статистику каждые show_every эпох; визуализирует кривые потерь (общей, контентной и стилевой) с помощью Matplotlib; возвращает итоговое стилизованное изображение и историю потерь.

Блок 8. Визуализация результатов.
После инициализации экземпляра NeuralStyleTransfer и загрузки изображений: отображаются исходные изображения контента и стиля; запускается процесс переноса стиля с заданными гиперпараметрами (число эпох, веса потерь, скорость обучения); показывается итоговое стилизованное изображение, полученное после оптимизации.


3)Ответ на контрольный вопрос: 14. Объясните принцип работы алгоритма Minimax. Где он применяется?
Minimax — алгоритм принятия решений для игр с нулевой суммой (выигрыш одного = проигрыш другого). Его цель: выбрать ход, минимизирующий максимальный возможный проигрыш при оптимальной игре противника.
Как работает:
1.Строит дерево всех возможных ходов от текущей позиции до конечных состояний.
2.Чередует роли: MAX (наш игрок) — максимизирует свой выигрыш; MIN (противник) — минимизирует выигрыш MAX.
3.В конечных узлах присваивает значения: +1 (победа MAX), −1 (победа MIN), 0 (ничья).
4.Поднимает значения к корню: на уровнях MAX выбирается максимум из дочерних узлов; на уровнях MIN — минимум.
5.В корне выбирает ход с максимальным значением.
Где применяется: компьютерные игры: шахматы, шашки, крестики‑нолики; теория игр и экономика: моделирование переговоров, аукционов, рыночных стратегий; робототехника: планирование действий в конкурентной среде (например, движение в потоке); кибербезопасность: анализ атак и защит («игра» злоумышленник vs система); оптимизация: принятие решений в условиях неопределённости (сценарий «наихудшего случая»).
