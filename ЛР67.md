АЛГОРИТМЫ СОРТИРОВКИ
СОРТИРОВКА ВЫБОРОМ (SELECTION SORT)
—алгоритм сортировки, который находит наименьший (или наибольший) элемент в массиве и перемещает его в начало (или конец). 
Алгоритм:
Внешний цикл: for (int i = 0; i < n - 1; ++i) проходит по каждому элементу массива слева направо и ищет минимальное значение среди оставшихся элементов, ставя его на правильное место.
Переменная minIndex: изначально равна текущему индексу внешнего цикла. Предполагается, что этот элемент является минимальным среди оставшихся элементов.
Во внутреннем цикле: for (int j = i + 1; j < n; ++j) сравниваем оставшиеся элементы массива, начиная с следующей позиции после текущей. Если находим элемент, который меньше текущего кандидата на минимальное значение, сохраняем его индекс.
Обмен значениями оператором: std::swap(arr[i], arr[minIndex]) После завершения внутреннего цикла меняем местами найденный минимальный элемент и текущий элемент (если были найдены изменения).
Временная сложность алгоритма: O(n²), где n - количество элементов в массиве
Почему O(n²): Два вложенных цикла, где каждый из них в среднем или худшем случае зависит от n. Внутренний цикл может выполняться до n раз для каждого из n итераций внешнего цикла, что приводит к квадратичной зависимости.

СОРТИРОВКА ОБМЕНОМ (ПУЗЫРЬКОМ) (BUBBLE SORT)
—простой алгоритм сортировки, основанный на попарном сравнении соседних элементов.
Алгоритм:
Первый цикл (for i in range(n)): Внешний цикл контролирует общее количество полных обходов массива. 
Использование флага для оптимизации (swapped): Этот флаг помогает определить, происходили ли замены на текущей итерации. 
Второй цикл (for j in range(0, n-i-1)): Внутренний цикл проходит по массиву, сравнивая каждый элемент с последующим. 
Сравнение и обмен элементов: if arr[j] > arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j] Если текущий элемент больше своего правого соседа, происходит обмен позиций. 
Раннее прекращение сортировки: if not swapped: break Если внутри второго цикла не было сделано ни одной перестановки, значит, массив уже отсортирован, и нет смысла продолжать обработку.
Временная сложность алгоритма: O(n^2), где n— длина массива.
Почему O(n²):  Цикл совершает n-1итераций. Для каждого элемента внешней итерации внутренний цикл проходит по остаточной части массива, осуществляя необходимое количество сравнений и, возможно, обменов. В худшем случае (если массив расположен в обратном порядке) внутренний цикл пройдёт по каждому элементу, сделав примерно (n-1)+(n-2)+⋯+1=(n(n-1))/2сравнений.

СОРТИРОВКА ВСТАВКАМИ (INSERTION SORT)
—простой алгоритм сортировки, который строит отсортированный массив (или список), вставляя каждый новый элемент в уже отсортированную последовательность.
Алгоритм:
Основной цикл: for i in range(1, len(arr)): проходит по каждому элементу массива, начиная со второго элемента (первый элемент изначально считается отсортированным) и вставляет его в правильную позицию среди уже отсортированных элементов.
Внутри вложенного цикла (сдвиги элементов): while j >= 0 and key < arr[j]: мы "пробегаем" по уже отсортированной части массива, сдвигая элементы вправо, пока не найдём место для вставки key. Во вставке элемента(обмен): arr[j + 1] = key мы вставляем наш текущий элемент (key) в правильную позицию, которую определили на предыдущем шаге.
Временная сложность алгоритма: O(n^2), где n— длина массива.
Почему O(n²): Цикл проходит n-1итераций. На каждой итерации внешнего цикла, внутренний цикл ищет правильное место для текущего элемента, сдвигая элементы в отсортированной части массива вправо. В худшем случае (обратный порядок элементов) этот цикл придётся повторять почти для каждого элемента, совершая примерно (n-1)+(n-2)+...+1=(n(n-1))/2≈n^2/2операций.

СОРТИРОВКА СЛИЯНИЕМ (MERGE SORT)
— алгоритм, который состоит в разделении массива пополам, сортировке половин и их слиянии.
Алгоритм:
Внешний цикл(рекурсивная функция void mergeSort(vector<int>& arr, int left, int right)) разделяет массив на мелкие части, отсортировывает их, а потом сливает их обратно.
Внутренний цикл(функция void merge(vector<int>& arr, int left, int mid, int right)) создаёт единый отсортированный массив.
Фактического обмена (swap) элементов в традиционном смысле тут нет. Вместо этого происходит процесс переноса элементов из временных массивов (L и R) обратно в исходный массив (arr).
Временная сложность алгоритма: O(n log n) , где n— количество элементов в массиве
Почему O(n log n): В процессе сортировки слиянием массив многократно делится на две части, вплоть до отдельных элементов. Глубина рекурсии (количество уровней деления) равна примерно 〖log⁡〗_2 n. Также на каждом уровне рекурсии происходит слияние двух отсортированных частей. Слияние двух отсортированных массивов выполняется за линейное время O(k), где k— сумма длин этих двух массивов.

СОРТИРОВКА ШЕЛЛА (SHELLSORT)
 — алгоритм, который является модификацией сортировки вставками, сортирует между собой элементы, стоящие на местах, кратных определённому шагу.
Алгоритм:
Внешний цикл: while gap > 0: контролирует изменение шага (gap).
Внутренний цикл: for i in range(gap, len(arr)): осуществляет просмотр массива, начиная с позиции, равной текущему шагу (gap), и проходя по остальным элементам.
Подцикл внутри внешнего цикла: while j >= gap and arr[j-gap] > temp: отвечает за перемещение элементов массива.
Обмен элементов: arr[j] = arr[j-gap] передвигает элемент, находящийся на расстоянии шага (gap), на позицию j, тем самым освобождая место для вставки текущего элемента (temp).
Обмен элементов: arr[j] = temp помещает элемент temp на позицию j, которая теперь свободна после сдвига предыдущих элементов.
Временная сложность: O(n²), где n— количество элементов в массиве.
Почему O(n²): Алгоритм использует вложенные циклы, но внутренний цикл не всегда проходит n раз, как в пузырьке.

БЫСТРАЯ СОРТИРОВКА (QUICK SORT)
— один из самых известных и широко используемых алгоритмов сортировки, который состоит в выборе опорного элемента, разделении массива на две части относительно опорного и в сортировке полученных частей рекурсивным вызовом себя от них. 
Алгоритм:
Внешнего цикла нет - весь процесс управляется рекурсией. Каждая рекурсивная ветка формирует собственные локальные объекты Массив делится на три части: left: элементы, меньшие опорного. middle: элементы, равные опорному. right: элементы, большие опорного.
Внутренние циклы скрыты в list comprehensions: Конструкция [x for x in arr if ...] выполняет перебор элементов массива и фильтрацию, действуя как неявный цикл. Каждый такой цикл создаёт новую часть массива, разделяя его по условию (меньше, равно, больше опорного элемента).
Обмена элементов нет в привычной форме (через оператор swap()). Вместо этого происходит создание новых объектов (left, middle, right), которые впоследствии объединяются. Старый массив не модифицируется на месте, а формируется новый отсортированный объект.
Временная сложность: O(n²), где n— количество элементов в массиве.
Почему O(n²): В редких случаях, когда массив уже отсортирован или почти отсортирован, а опорный элемент выбирается неудачно, алгоритм может столкнуться с проблемой постоянного неравновесного разделения массива на очень маленькую и очень большую части. В этом случае каждая рекурсия уменьшит массив всего на один элемент, и получится ∑_(i=1)^n(n-i)=O(n^2)операций.

ПИРАМИДАЛЬНАЯ СОРТИРОВКА (HEAP SORT) 
 —алгоритм сортировки массива произвольных элементов, основанный на структуре данных двоичной кучи.
Алгоритм:
Функция(внешний цикл): void heapify(vector<int>& arr, int n, int root): предназначена для поддержания свойств кучи. Она получает массив (arr), его размер (n) и индекс корневого узла (root), и восстанавливает кучу, следуя принципу: родитель всегда больше детей.
Функция: void heapSort(vector<int>& arr): организует процесс сортировки, состоящий из двух главных этапов: создает max-кучу и выполняет сортировку.
Обмен элементов происходит, если нарушено свойство кучи (родитель меньше ребёнка): swap(arr[root], arr[largest]).
Явного внутреннего цикла нет, так как структура данных поддерживается рекурсивно.
Временная сложность — O(nlog⁡n), где n— количество элементов в массиве.
Почему O(nlog⁡n): Сначала исходный массив преобразуется в бинарную кучу. Это делается за время O(n), поскольку максимальная высота бинарного дерева равна log⁡n. После того, как куча построена, каждый раз мы извлекаем наибольший элемент (корень кучи) и восстанавливаем структуру кучи. Операция извлечения и восстановления занимает время O(log⁡n), так как она сводится к изменению высоты дерева, равной log⁡n.

АЛГОРИТМЫ ПОИСКА
ПОСЛЕДОВАТЕЛЬНЫЙ (ЛИНЕЙНЫЙ) ПОИСК
 —это простой алгоритм поиска элемента в списке путём последовательного просмотра всех элементов до нахождения искомого или исчерпания списка.
Алгоритм:
Функция linear_search(arr, target) принимает два параметра:  arr — список, в котором нужно найти элемент. target — искомое значение.
Внешний цикл: for index, value in enumerate(arr): проходит по каждому элементу списка arr, попутно извлекая его индекс (index) и значение (value).
Условие поиска (if value == target): Если текущий элемент (value) совпадает с искомым значением (target), мы сразу возвращаем его индекс (index).
Временная сложность: O(n), где n — количество элементов в массиве.
Почему O(n): Линейный поиск подразумевает последовательный перебор элементов списка, начиная с первого и до последнего включительно. В худшем случае (искомый элемент находится в конце списка или вообще отсутствует) алгоритм вынужден проверить каждый элемент, затратив n операций сравнения.

БИНАРНЫЙ (ДВОИЧНЫЙ, ДИХОТОМИЧЕСКИЙ) ПОИСК
— это поиск заданного элемента на упорядоченном множестве, осуществляемый путём неоднократного деления этого множества на две части таким образом, что искомый элемент попадает в одну из этих частей. 
Алгоритм:
Функция: int binarySearch(const vector<int>& arr, int target): реализует алгоритм бинарного поиска для нахождения элемента в отсортированном массиве.
Мы устанавливаем две переменные для отслеживания границ поиска: low и high.
Внутри цикла while(low <= high) сужается область поиска: вычисляется середина массива, сравнивается средний элемент с искомым, в зависимости от результата сравнения корректируются границы поиска.
Временная сложность: O(log⁡n), где n— количество элементов
Почему O(log⁡n): На каждом шаге алгоритм уменьшает пространство поиска в два раза. Если изначально массив состоял из n элементов, то после первого шага останется примерно n/2, после второго — n/4, и так далее. Количество шагов, необходимых для поиска, эквивалентно количеству делений массива пополам, пока не останется один элемент. Это соответствует высоте бинарного дерева, равной 〖log⁡〗_2 n. 

ИНТЕРПОЛИРУЮЩИЙ ПОИСК
— это алгоритм поиска, который предсказывает позицию нужного элемента на основе разницы значений.
Алгоритм:
Функция: int interpolationSearch(const vector<int>& arr, int target): получает на входе отсортированный массив и искомое значение.
С помощью цикла while выполняет поиск, пока нижняя граница (low) не пересеклась с верхней (high) и пока искомый элемент находится в пределах установленных границ. Вычисляет приблизительный индекс (pos), проверяет его значение и в зависимости от результата сдвигает границы поиска влево или вправо.
Краткая формула оценки позиции:
pos=low+((high-low)×(target-arr[low]))/((arr[high]-arr[low]))
Где:
	low — нижняя граница поиска,
	high — верхняя граница поиска,
	target — искомое значение,
	arr[low] и arr[high] — значения на границах поиска.
Временная сложность: O(n), где n— количество элементов
Почему O(n): если элементы массива распределены неравномерно (например, сосредоточены в одном сегменте), интерполирующий поиск теряет свою эффективность и может потребовать полного сканирования массива.

ПОИСК ПО ФИБОНАЧЧИ
 — это эффективный алгоритм поиска, используемый для нахождения целевого значения в отсортированной коллекции, такой как массив или список. По принципу он аналогичен бинарному поиску, но использует числа Фибоначчи для определения позиций для сравнения.
Алгоритм:
Внутренняя функция def fib_m(m) вычисляет m-е число Фибоначчи. Она инициализирует первые два числа Фибоначчи, используемые для определения шагов(f_minus_2 = 0, f_minus_1 = 1) и на каждой итерации вычисляет следующее число Фибоначчи, пока не дойдет до m-го члена.
Основная функция: def fibonacci_search(arr, target): находит минимальное число Фибоначчи, которое больше или равно длине массива. Это нужно для того, чтобы установить подходящие шаги для поиска.
Временная сложность: O(log⁡n), где n— количество элементов в массиве.
Почему O(log⁡n): Поиск по Фибоначчи аналогичен бинарному поиску в плане деления массива на части, но делит его на части, размеры которых соответствуют числам Фибоначчи. Это означает, что на каждом шаге длина подлежащего исследованию фрагмента массива уменьшается, как и в бинарном поиске, но по другому закону.
